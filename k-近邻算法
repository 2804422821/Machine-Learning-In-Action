
from numpy import *
import operator
from os import listdir

def classify0(inX, dataSet, labels, k):  # 分类函数，参数为输入向量，训练数据向量集合，标签向量集合，距离输入向量最近点的数目
    # 距离计算
    dataSize = dataSet.shape[0]  # 获取训练数据向量集合矩阵的行数
    diffMat = tile(inX, (dataSize, 1)) - dataSet  # tile()方法根据dataSet形状构造矩阵
    sqDiffMat = diffMat ** 2
    sqDistances = sqDiffMat.sum(axis=1)  # sum()方法计算矩阵行上的数据和
    distances = sqDistances ** 0.5  # 距离列表
    sortedDisIndices = distances.argsort()  # 对距离的大小值进行排序
    classCount = {}  #
    # 由小到大取出前k个值，并构造dic记录每个距离所对应标签出现的频率
    for i in range(k):
        votelLabel = labels[sortedDisIndices[i]]
        classCount[votelLabel] = classCount.get(votelLabel, 0) + 1
    # 对标签出现频率进行排序
    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)
    # 得到频率最高值所对应的标签
    return sortedClassCount[0][0]

# 创建训练数据集和标签向量集合
def createDataSet():
    group = array([[0, 0], [0, 0.1], [1.0, 1.0], [1.0, 1.1]])

labels = ['A', 'A', 'B', 'B']
    return group, labels
    
#文本记录数据集解析程序
def file2Matrix(fileName):
    #读取文本文件，构造数据集矩阵，标签向量集合
    fr = open(fileName)
    arrayOfLines = fr.readlines()
    numberOfLines = len(arrayOfLines)
    returnMat = zeros((numberOfLines, 3))     #zero()方法根据形状返回矩阵
    classLabelVector = []
    index = 0
    for line in arrayOfLines:
        line = line.strip()
        listFromLine = line.split('\t')      #split()方法，根据字符串中的函数参数划分成列表元素，并返回这个列表
        returnMat[index,:] = listFromLine[0:3]     #将listFromLine的前3个特征值元素传给returnMat
        # 将listFromLine的最后一个特征值元素(标签)传给classLabelVector，并将最后一个特征值转化为整数型处理
        label = 0
        if listFromLine[-1] == 'didntLike':
            label = 1
        elif listFromLine[-1] == 'smallDoses':
            label = 2
        else:
            label = 3
        classLabelVector.append(label)
        index += 1
    return returnMat, classLabelVector
    
#归一化特征值，为了减少某个特征值的数值带来的影响
def autoNorm(dataSet):
    #计算矩阵行的和或列的最大值和最小值
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    #归一化特征值公式，(vals - minVals)/(maxVals - minVals)
    ranges = maxVals - minVals
    normDataSet = zeros(shape(dataSet))
    m = normDataSet.shape[0]
    normDataSet = dataSet - tile(minVals, (m,1))
    normDataSet = normDataSet / tile(ranges, (m,1))
    return normDataSet, ranges, minVals

#分类器测试代码
def datingClassTest():
    hoRatio = 0.5     #选择数据样本中，数据集和输入向量所占比
    dataMat, dataLabel = file2Matrix('datingTestSet.txt')
    normMat, ranges, minVals = autoNorm(dataMat)
    m = normMat.shape[0]
    numTestVecs = int(m*hoRatio)
    errorCount = 0.
    #输入向量集合中的每个单位进行分类，并与之对应的标签进行比较，计算出总体上的算法正确率
    for i in range(numTestVecs):
        classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:], dataLabel[numTestVecs:m], 3)
        print('the classifier came back with: %d, the real answer is: %d' %(classifierResult, dataLabel[i]))
        #记录出错的数据
        if classifierResult != dataLabel[i]:
            errorCount += 1.0
    print('the total error rate is: %f' %(errorCount/float(numTestVecs)))
    print(errorCount)


#手写数字识别系统的的测试
def handWritingClassTest():
    #获取目录的内容
    hwLabels = []
    trainingFileList = listdir('trainingDigits')
    m = len(trainingFileList)
    trainingMat = zeros((m, 1024))
    #从文件名中获取分类数字标签
    for i in range(m):
        fileNameStr = trainingFileList[i]
        fileStr = fileNameStr.split('.')[0]
        classNumStr = int(fileStr.split('_')[0])
        hwLabels.append(classNumStr)
        trainingMat[i,:] = image2Vector('trainingDigits/%s' %fileNameStr)
    testFileList = listdir('testDigits')
    mTest = len(testFileList)
    errorCount = 0.0
    #测试数据文件名作为正确标签，用其作为输入向量检测分类算法的正确率
    for i in range(mTest):
        fileNameStr = testFileList[i]
        fileStr = fileNameStr.split('.')[0]
        classNumStr = int(fileStr.split('_')[0])
        vectorUnderTest = image2Vector('trainingDigits/%s' %fileNameStr)
        classifyResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)
        print('the classify came back with: %d, the real answer is: %d' %(classifyResult, classNumStr))
        if classifyResult != classNumStr: errorCount += 1.0
        #计算出分类算法的正确率
    print('the total number of error is: %d' %errorCount)
    print('the total error rate is: %f' %(errorCount/mTest))
